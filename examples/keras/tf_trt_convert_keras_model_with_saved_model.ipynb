{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ivr1tyX11K4a"
   },
   "source": [
    "# TF-TRT(TnsorFlow with TensorTRT)を使ってKerasモデルをFP16で最適化する\n",
    "TensorFlow 1.14 / TensorRT 5.1.5\n",
    "\n",
    "create_inference_graph は非推奨となり、trt_convert.TrtGraphConverterを使うことが推奨となったので対応する。<br>\n",
    "tf.kerasのMobileNet V2のモデルをTrtGraphConverterによってFP16で最適化する。<br>\n",
    "\n",
    "以下を参考にしました。\n",
    "- [How to run Keras model on Jetson Nano](https://www.dlology.com/blog/how-to-run-keras-model-on-jetson-nano/)\n",
    "- [Accelerating Inference In TF-TRT User Guide](https://docs.nvidia.com/deeplearning/frameworks/tf-trt-user-guide/index.html)\n",
    "- [High performance inference with TensorRT Integration](https://medium.com/tensorflow/high-performance-inference-with-tensorrt-integration-c4d78795fbfe)\n",
    "- [High performance inference with TensorRT Integration](https://vengineer.hatenablog.com/entry/71944882)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EHsNV10fBUV1"
   },
   "source": [
    "MobileNet v2 benchmark.<br>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qnjNXzFkDaHu"
   },
   "source": [
    "GPU (Env.) |Keras pre-trainded model | TF-TRT model\n",
    "--- | --- | ---\n",
    "NVIDIA Tesla T4 (with google colab) | 9.81 ms | 4.25 ms\n",
    "NVIDIA GTX1070 (My PC , CPU: Ryzen 17000) |  15.69 ms | 4.30 ms\n",
    "NVIDIA Jetson Nano | 85.72 ms | 10.41 ms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s_ePzeZdkyee"
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P9FtaqQx8-Uy"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from distutils.version import StrictVersion\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kln1UpKrldbe"
   },
   "source": [
    "tensorflow.python.compiler.tensorrt はTensorFlow version 1.14からなのでバージョンチェックを行う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LrGlXO4u9WnP"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)\n",
    "if StrictVersion(tf.__version__) < StrictVersion('1.14.0'):\n",
    "    raise ImportError('Please upgrade your TensorFlow installation to v1.14.*.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n1UoY8jl_k6_"
   },
   "source": [
    "tensorflow.python.compiler.tensorrt はTrtGraphConverterで最適化するために必要。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FUdev5_dkuSC"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.compiler.tensorrt import trt_convert\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input, decode_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_2QDN0G1pB0T"
   },
   "source": [
    "# Load model and predict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jtXE-q76mX57"
   },
   "source": [
    "KerasのMobileNet v2のモデルをロードする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J28gmyCpAgH_"
   },
   "outputs": [],
   "source": [
    "MODEL_DIR = os.path.join('.', 'model')\n",
    "MODEL_NAME = 'mobilenet_v2.h5'\n",
    "\n",
    "MODEL_PATH = os.path.join(MODEL_DIR, MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nYie9lBxFcsg"
   },
   "outputs": [],
   "source": [
    "model = MobileNetV2(weights='imagenet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4Ghu7W0fsUF1"
   },
   "source": [
    "ロードしたモデルを使って推論する。<br>\n",
    "keras-applicationのサンプル画像を使って推論を行う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fVkt26V-o-0b"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/keras-team/keras-applications.git\n",
    "!ls -al ./keras-applications/tests/data/elephant.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_1A89LYys5cG"
   },
   "outputs": [],
   "source": [
    "# Display image.\n",
    "image_path = './keras-applications/tests/data/elephant.jpg'\n",
    "\n",
    "image = Image.open(image_path)\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a6iOyOADtOzg"
   },
   "outputs": [],
   "source": [
    "# Predict\n",
    "img = tf.keras.preprocessing.image.load_img(image_path, target_size=(224, 224))\n",
    "x = tf.keras.preprocessing.image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "preds = model.predict(x)\n",
    "\n",
    "print('Predicted:', decode_predictions(preds, top=3)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V_qcn8eUskNy"
   },
   "source": [
    "推論を100回実行して平均時間(ミリ秒)を求める。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HDeetTlxsjMc"
   },
   "outputs": [],
   "source": [
    "times = []\n",
    "for i in range(100):\n",
    "    start_tm = time.time()\n",
    "    model.predict(x)\n",
    "    times.append(time.time() - start_tm)\n",
    "    \n",
    "print('Mean inference time: {0:.2f} ms'.format(np.array(times).mean() * 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AnfMFSb01K5F"
   },
   "source": [
    "モデルを保存する。<br>\n",
    "tf.keras.experimental.export_saved_model をつかってSavedModel formatで保存する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7-Z3YTICIc03"
   },
   "outputs": [],
   "source": [
    "# Make save model dir.\n",
    "if os.path.exists(MODEL_DIR):\n",
    "    shutil.rmtree(MODEL_DIR)\n",
    "os.mkdir(MODEL_DIR)\n",
    "\n",
    "tf.keras.experimental.export_saved_model(model, MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9ldsbO0S1K5K"
   },
   "outputs": [],
   "source": [
    "!ls -al model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "29lJ7FiS1K5O"
   },
   "source": [
    "TF-TRTに変換した後のモデルで使用するためのinput/outputの名前を得る。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "erPLUBdj1K5P"
   },
   "outputs": [],
   "source": [
    "input_names = [t.op.name for t in model.inputs]\n",
    "output_names = [t.op.name for t in model.outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5FupDi1x1K5S"
   },
   "outputs": [],
   "source": [
    "# Prints input and output nodes names, take notes of them.\n",
    "print(input_names, output_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3iUdtMKNpIwy"
   },
   "source": [
    "# Convert tf-trt model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RDTgxb6Q1K5X"
   },
   "source": [
    "保存したh5モデルをロードし、FreezeGraph形式に変換する。<br>\n",
    "FreezeGarph形式をTrtGraphConverterで最適化する。<br>\n",
    "\n",
    "**Note:**\n",
    "- h5モデルを直接変換することはできない。\n",
    "- SavedModel形式で保存したものをTrtGraphConverterでロードして最適化する。\n",
    "- 最適化後はFreezeGraph形式で保存する。<br>\n",
    "まだKerasのモデルでロード、実行はできない模様。<br>\n",
    "TF2.0になればKerasでの実行がメインになるので対応してほしい(けどそれはTensorRTでよいのか？)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6F0OZRK9F_Xo"
   },
   "outputs": [],
   "source": [
    "# Clear any previous session.\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# This line must be executed before loading Keras model.\n",
    "# See NVIDIA document(https://docs.nvidia.com/deeplearning/frameworks/tf-trt-user-guide/index.html#best-practices)\n",
    "tf.keras.backend.set_learning_phase(0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mC5mxamFxasf"
   },
   "source": [
    "# Convert TF-TRT\n",
    "\n",
    "TrtGraphConverterを使ってモデルを最適化します。<br>\n",
    "ここではFP16に変換するように指定します。<br>\n",
    "最適化後、save()メソッドを使ってモデルをSavedModel形式で保存します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sbyi4N8eyfsF"
   },
   "outputs": [],
   "source": [
    "SAVED_MODEL_PATH = os.path.join(MODEL_DIR, 'moblienet_v2_trt.pb')\n",
    "# OUTPUT_SAVED_MODEL_DIR = os.path.join('.', 'tf_trt_saved_model_moblienet_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m-6XXDFRA6W-"
   },
   "outputs": [],
   "source": [
    "converter = trt_convert.TrtGraphConverter(\n",
    "    input_saved_model_dir=MODEL_DIR,\n",
    "    nodes_blacklist=output_names, #output nodes\n",
    "    max_batch_size=1,\n",
    "    is_dynamic_op=True,\n",
    "    max_workspace_size_bytes=trt_convert.DEFAULT_TRT_MAX_WORKSPACE_SIZE_BYTES,\n",
    "    precision_mode=trt_convert.TrtPrecisionMode.FP16,\n",
    "    minimum_segment_size=3)\n",
    "trt_graph = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AUyl8r8C1K5y"
   },
   "outputs": [],
   "source": [
    "with open(SAVED_MODEL_PATH, 'wb') as f:\n",
    "    f.write(trt_graph.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g2EFTsubNnOb"
   },
   "outputs": [],
   "source": [
    "!ls -al model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TKVTfx5i1K54"
   },
   "source": [
    "# Run TF-TRT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VrEfWGsjOJpG"
   },
   "outputs": [],
   "source": [
    "def get_frozen_graph(graph_file):\n",
    "    \"\"\"Read Frozen Graph file from disk.\"\"\"\n",
    "    with tf.gfile.GFile(graph_file, \"rb\") as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "    return graph_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CPWlfc41L310"
   },
   "outputs": [],
   "source": [
    "# Create session and load graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "trt_graph = get_frozen_graph(SAVED_MODEL_PATH)\n",
    "\n",
    "tf_config = tf.ConfigProto()\n",
    "tf_config.gpu_options.allow_growth = True\n",
    "tf_sess = tf.Session(config=tf_config)\n",
    "tf.import_graph_def(trt_graph, name='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9J_Gk7gFNE5z"
   },
   "outputs": [],
   "source": [
    "# Get graph input size\n",
    "for node in trt_graph.node:\n",
    "    if 'input_' in node.name:\n",
    "        size = node.attr['shape'].shape\n",
    "        image_size = [size.dim[i].size for i in range(1, 4)]\n",
    "        break\n",
    "print(\"image_size: {}\".format(image_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RPfq7HybMsTu"
   },
   "outputs": [],
   "source": [
    "# input and output tensor names.\n",
    "output_names = ['Logits/Softmax']\n",
    "input_names = ['input_1']\n",
    "\n",
    "input_tensor_name = input_names[0] + \":0\"\n",
    "output_tensor_name = output_names[0] + \":0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BAM4ZVqW1K6I"
   },
   "outputs": [],
   "source": [
    "print(\"input_tensor_name: {}\\noutput_tensor_name: {}\".format(\n",
    "    input_tensor_name, output_tensor_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MxdvHSkYNJbQ"
   },
   "outputs": [],
   "source": [
    "output_tensor = tf_sess.graph.get_tensor_by_name(output_tensor_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H0xhCjKV1K6P"
   },
   "outputs": [],
   "source": [
    "# tf.saved_model.loader.load(\n",
    "#         tf_sess, [tf.saved_model.tag_constants.SERVING], OUTPUT_SAVED_MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e10nc3Sn3Gj6"
   },
   "outputs": [],
   "source": [
    "img = tf.keras.preprocessing.image.load_img(image_path, target_size=image_size[:2])\n",
    "x = tf.keras.preprocessing.image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "feed_dict = {\n",
    "    input_tensor_name: x\n",
    "}\n",
    "preds = tf_sess.run(output_tensor, feed_dict)\n",
    "\n",
    "# decode the results into a list of tuples (class, description, probability)\n",
    "# (one such list for each sample in the batch)\n",
    "print('Predicted:', decode_predictions(preds, top=3)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uVfrMZQA1K6X"
   },
   "outputs": [],
   "source": [
    "times = []\n",
    "for i in range(100):\n",
    "    start_tm = time.time()\n",
    "    tf_sess.run(output_tensor, feed_dict)\n",
    "    times.append(time.time() - start_tm)\n",
    "    \n",
    "print('Inference : {0:.2f} ms'.format(np.array(times).mean() * 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gMZLAt0y3VDF"
   },
   "source": [
    "保存したモデルをロードする。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9SAj-zNS1K6a"
   },
   "source": [
    "# 失敗したこと"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BoVLh6tV_3SO"
   },
   "source": [
    "- TrtGraphConverter.save を使ってSavedModel形式で保存→読み込みをする。<br>\n",
    "tf.saved_model.loader.loadまたは、sess.runで無限待ちしてしまう。\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "tf_trt_convert_keras_model_with_saved_model_v2.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
